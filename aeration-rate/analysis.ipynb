{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/train_dataset.csv\")\n",
    "\n",
    "data['is_test'] = False\n",
    "evaluation = pd.read_csv(\"./data/evaluation_public.csv\")\n",
    "evaluation['is_test'] = True\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "\n",
    "all_data = pd.concat([data, evaluation]).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 特征处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "all_data['date'] = pd.to_datetime(all_data['time'])\n",
    "all_data['hour'] = all_data['date'].dt.hour\n",
    "all_data['year'] = all_data['date'].dt.year\n",
    "all_data['month'] = all_data['date'].dt.month\n",
    "all_data['minute'] = all_data['date'].dt.minute\n",
    "all_data['weekday'] = all_data['date'].dt.weekday\n",
    "all_data['day'] = all_data['date'].dt.day\n",
    "all_data['hour'] = all_data['date'].dt.hour\n",
    "all_data['ts'] = all_data['hour']*3600 + all_data['minute']*60 + all_data['date'].dt.second"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# year','month','day','hour',\n",
    "features = [ 'JS_NH3', 'CS_NH3', 'JS_TN', 'CS_TN', 'JS_LL', 'CS_LL', 'MCCS_NH4', 'MCCS_NO3', 'JS_COD', 'CS_COD', 'JS_SW', 'CS_SW', 'B_HYC_NH4', 'B_HYC_XD', 'B_HYC_MLSS', 'B_HYC_JS_DO', 'B_HYC_DO', 'B_CS_MQ_SSLL', 'B_QY_ORP', 'N_HYC_NH4', 'N_HYC_XD', 'N_HYC_MLSS', 'N_HYC_JS_DO', 'N_HYC_DO', 'N_CS_MQ_SSLL', 'N_QY_ORP','weekday','hour', 'ts']\n",
    "features = [f for f in features if f not in ['time', 'Label1', 'Label2','Label1_log','Label2_log','CS_LL',\n",
    "                                              'B_QY_ORP','JS_TN', 'CS_SW','MCCS_NH4','N_HYC_JS_DO','MCCS_NO3','JS_SW',\n",
    "                                             ]]\n",
    "\n",
    "labels = ['Label1', 'Label2']\n",
    "train = all_data[~all_data['is_test']].copy(deep=True)\n",
    "test = all_data[all_data['is_test']].copy(deep=True)\n",
    "train = train.dropna(subset=['Label1', 'Label2']).reset_index(drop=True)\n",
    "test['is_train'] = False\n",
    "train['is_train'] = True\n",
    "data = pd.concat([train, test]).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# for x in features:\n",
    "#     if x not in ['weekday','hour', 'ts']:\n",
    "#         plt.figure(1, figsize=(4, 10))\n",
    "#         data[x][-30000:].plot()\n",
    "#         plt.show()\n",
    "#         plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38125\\AppData\\Local\\Temp/ipykernel_67520/1297101366.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{f}_{f_mean_name}_cha'] = data[f] - data[f_mean_name]\n",
      "C:\\Users\\38125\\AppData\\Local\\Temp/ipykernel_67520/1297101366.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{f}_{f_max_name}_cha'] = data[f] - data[f_max_name]\n",
      "C:\\Users\\38125\\AppData\\Local\\Temp/ipykernel_67520/1297101366.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'{f}_{f_min_name}_cha'] = data[f] - data[f_min_name]\n",
      "C:\\Users\\38125\\AppData\\Local\\Temp/ipykernel_67520/1297101366.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f_mean_name] = train_rolling.mean().fillna(0).values\n",
      "C:\\Users\\38125\\AppData\\Local\\Temp/ipykernel_67520/1297101366.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f_max_name] = train_rolling.max().fillna(0).values\n",
      "C:\\Users\\38125\\AppData\\Local\\Temp/ipykernel_67520/1297101366.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f_min_name] = train_rolling.min().fillna(0).values\n",
      "C:\\Users\\38125\\AppData\\Local\\Temp/ipykernel_67520/1297101366.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f_std_name] = train_rolling.std().fillna(0).values\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "i = 0\n",
    "add_featuers = []\n",
    "length = 0\n",
    "for f in ['JS_NH3', 'CS_NH3', 'CS_TN', 'JS_LL', 'JS_COD', 'CS_COD', 'B_HYC_NH4', 'B_HYC_XD', 'B_HYC_MLSS', 'B_HYC_JS_DO', 'B_HYC_DO', 'B_CS_MQ_SSLL',\n",
    "          'N_HYC_NH4', 'N_HYC_XD', 'N_HYC_MLSS', 'N_HYC_DO', 'N_CS_MQ_SSLL', 'N_QY_ORP']:\n",
    "    for r in [7]:\n",
    "        train_rolling = data[f].rolling(window=r, center=True)\n",
    "        f_mean_name = 'rolling{}_{}_mean'.format(r,f)\n",
    "        f_max_name = 'rolling{}_{}_max'.format(r,f)\n",
    "        f_min_name = 'rolling{}_{}_min'.format(r,f)\n",
    "        f_std_name = 'rolling{}_{}_std'.format(r,f)\n",
    "        data[f_mean_name] = train_rolling.mean().fillna(0).values\n",
    "        data[f_max_name] = train_rolling.max().fillna(0).values\n",
    "        data[f_min_name] = train_rolling.min().fillna(0).values\n",
    "        data[f_std_name] = train_rolling.std().fillna(0).values\n",
    "        data[f'{f}_{f_mean_name}_cha'] = data[f] - data[f_mean_name]\n",
    "        data[f'{f}_{f_max_name}_cha'] = data[f] - data[f_max_name]\n",
    "        data[f'{f}_{f_min_name}_cha'] = data[f] - data[f_min_name]\n",
    "        if i == 0:\n",
    "            add_featuers.append(f_mean_name)\n",
    "            add_featuers.append(f_max_name)\n",
    "            add_featuers.append(f_min_name)\n",
    "            add_featuers.append(f_std_name)\n",
    "            add_featuers.append(f'{f}_{f_mean_name}_cha')\n",
    "            add_featuers.append(f'{f}_{f_max_name}_cha')\n",
    "            add_featuers.append(f'{f}_{f_min_name}_cha')\n",
    "features.extend(add_featuers)\n",
    "\n",
    "# 对所有的特征进行划分\n",
    "for f in features:\n",
    "    if f not in ['weekday','hour', 'ts']:\n",
    "        data[f] = pd.qcut(data[f], q=100, labels=False, duplicates=\"drop\")\n",
    "\n",
    "train = data[data['is_train']].reset_index(drop=True)\n",
    "test = data[~data['is_train']].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "train = train.dropna(subset=['Label1', 'Label2']).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "                  time  JS_NH3  CS_NH3    JS_TN  CS_TN  JS_LL      CS_LL  \\\n0      2022/4/30 16:00    99.0    92.0  52.8394   77.0   27.0  2204.6711   \n1       2022/5/2 16:00    50.0    92.0  40.1798   49.0   80.0  1410.1064   \n2       2022/5/3 16:00    69.0    91.0  46.6933   78.0   20.0  2112.2976   \n3       2022/5/4 16:00    91.0    86.0  52.6615   76.0   61.0   875.0145   \n4       2022/5/5 16:00    77.0    73.0  48.7988   62.0   34.0  1495.3458   \n...                ...     ...     ...      ...    ...    ...        ...   \n35063   2022/7/18 2:30    49.0    60.0  30.2603   27.0    8.0  1111.9569   \n35064   2022/7/18 2:32    49.0    60.0  30.2603   27.0   10.0  1680.4688   \n35065   2022/7/18 2:34    49.0    60.0  30.2603   27.0    8.0  1633.5309   \n35066   2022/7/18 2:36    49.0    60.0  30.2603   27.0    8.0  1247.8890   \n35067   2022/7/18 2:38    49.0    60.0  32.8130   27.0   35.0   998.9305   \n\n       MCCS_NH4  MCCS_NO3  JS_COD  ...  \\\n0        0.0010    8.5796    99.0  ...   \n1        0.1977    8.1337    59.0  ...   \n2        0.1978    8.3301    70.0  ...   \n3        0.2086    8.3724    90.0  ...   \n4        0.2059    7.4816    87.0  ...   \n...         ...       ...     ...  ...   \n35063    0.1428    9.0365    30.0  ...   \n35064    0.1425    9.0495    30.0  ...   \n35065    0.1425    9.0419    30.0  ...   \n35066    0.1425    9.0093    30.0  ...   \n35067    0.1425    9.0191    34.0  ...   \n\n       N_CS_MQ_SSLL_rolling7_N_CS_MQ_SSLL_mean_cha  \\\n0                                             98.0   \n1                                             98.0   \n2                                             97.0   \n3                                             83.0   \n4                                             28.0   \n...                                            ...   \n35063                                         19.0   \n35064                                         43.0   \n35065                                         73.0   \n35066                                         39.0   \n35067                                         18.0   \n\n       N_CS_MQ_SSLL_rolling7_N_CS_MQ_SSLL_max_cha  \\\n0                                            85.0   \n1                                            85.0   \n2                                            84.0   \n3                                            81.0   \n4                                            34.0   \n...                                           ...   \n35063                                        17.0   \n35064                                        45.0   \n35065                                        73.0   \n35066                                        49.0   \n35067                                        35.0   \n\n       N_CS_MQ_SSLL_rolling7_N_CS_MQ_SSLL_min_cha  rolling7_N_QY_ORP_mean  \\\n0                                            84.0                       0   \n1                                            84.0                       0   \n2                                            83.0                       0   \n3                                            45.0                       7   \n4                                             0.0                       9   \n...                                           ...                     ...   \n35063                                         7.0                      63   \n35064                                        15.0                      63   \n35065                                        37.0                      62   \n35066                                         9.0                      62   \n35067                                         0.0                      61   \n\n       rolling7_N_QY_ORP_max  rolling7_N_QY_ORP_min  rolling7_N_QY_ORP_std  \\\n0                          0                      0                      0   \n1                          0                      0                      0   \n2                          0                      0                      0   \n3                         24                      3                     94   \n4                         24                      4                     94   \n...                      ...                    ...                    ...   \n35063                     63                     63                     81   \n35064                     63                     62                     82   \n35065                     63                     62                     82   \n35066                     62                     61                     80   \n35067                     62                     60                     77   \n\n       N_QY_ORP_rolling7_N_QY_ORP_mean_cha  \\\n0                                     93.0   \n1                                     93.0   \n2                                     93.0   \n3                                      0.0   \n4                                      0.0   \n...                                    ...   \n35063                                 80.0   \n35064                                 19.0   \n35065                                 22.0   \n35066                                 23.0   \n35067                                 47.0   \n\n       N_QY_ORP_rolling7_N_QY_ORP_max_cha  N_QY_ORP_rolling7_N_QY_ORP_min_cha  \n0                                    49.0                                50.0  \n1                                    49.0                                50.0  \n2                                    49.0                                50.0  \n3                                     0.0                                50.0  \n4                                     0.0                                 0.0  \n...                                   ...                                 ...  \n35063                                20.0                                40.0  \n35064                                11.0                                34.0  \n35065                                10.0                                34.0  \n35066                                 9.0                                32.0  \n35067                                15.0                                32.0  \n\n[35068 rows x 165 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>JS_NH3</th>\n      <th>CS_NH3</th>\n      <th>JS_TN</th>\n      <th>CS_TN</th>\n      <th>JS_LL</th>\n      <th>CS_LL</th>\n      <th>MCCS_NH4</th>\n      <th>MCCS_NO3</th>\n      <th>JS_COD</th>\n      <th>...</th>\n      <th>N_CS_MQ_SSLL_rolling7_N_CS_MQ_SSLL_mean_cha</th>\n      <th>N_CS_MQ_SSLL_rolling7_N_CS_MQ_SSLL_max_cha</th>\n      <th>N_CS_MQ_SSLL_rolling7_N_CS_MQ_SSLL_min_cha</th>\n      <th>rolling7_N_QY_ORP_mean</th>\n      <th>rolling7_N_QY_ORP_max</th>\n      <th>rolling7_N_QY_ORP_min</th>\n      <th>rolling7_N_QY_ORP_std</th>\n      <th>N_QY_ORP_rolling7_N_QY_ORP_mean_cha</th>\n      <th>N_QY_ORP_rolling7_N_QY_ORP_max_cha</th>\n      <th>N_QY_ORP_rolling7_N_QY_ORP_min_cha</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022/4/30 16:00</td>\n      <td>99.0</td>\n      <td>92.0</td>\n      <td>52.8394</td>\n      <td>77.0</td>\n      <td>27.0</td>\n      <td>2204.6711</td>\n      <td>0.0010</td>\n      <td>8.5796</td>\n      <td>99.0</td>\n      <td>...</td>\n      <td>98.0</td>\n      <td>85.0</td>\n      <td>84.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93.0</td>\n      <td>49.0</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022/5/2 16:00</td>\n      <td>50.0</td>\n      <td>92.0</td>\n      <td>40.1798</td>\n      <td>49.0</td>\n      <td>80.0</td>\n      <td>1410.1064</td>\n      <td>0.1977</td>\n      <td>8.1337</td>\n      <td>59.0</td>\n      <td>...</td>\n      <td>98.0</td>\n      <td>85.0</td>\n      <td>84.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93.0</td>\n      <td>49.0</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022/5/3 16:00</td>\n      <td>69.0</td>\n      <td>91.0</td>\n      <td>46.6933</td>\n      <td>78.0</td>\n      <td>20.0</td>\n      <td>2112.2976</td>\n      <td>0.1978</td>\n      <td>8.3301</td>\n      <td>70.0</td>\n      <td>...</td>\n      <td>97.0</td>\n      <td>84.0</td>\n      <td>83.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93.0</td>\n      <td>49.0</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022/5/4 16:00</td>\n      <td>91.0</td>\n      <td>86.0</td>\n      <td>52.6615</td>\n      <td>76.0</td>\n      <td>61.0</td>\n      <td>875.0145</td>\n      <td>0.2086</td>\n      <td>8.3724</td>\n      <td>90.0</td>\n      <td>...</td>\n      <td>83.0</td>\n      <td>81.0</td>\n      <td>45.0</td>\n      <td>7</td>\n      <td>24</td>\n      <td>3</td>\n      <td>94</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022/5/5 16:00</td>\n      <td>77.0</td>\n      <td>73.0</td>\n      <td>48.7988</td>\n      <td>62.0</td>\n      <td>34.0</td>\n      <td>1495.3458</td>\n      <td>0.2059</td>\n      <td>7.4816</td>\n      <td>87.0</td>\n      <td>...</td>\n      <td>28.0</td>\n      <td>34.0</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>24</td>\n      <td>4</td>\n      <td>94</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35063</th>\n      <td>2022/7/18 2:30</td>\n      <td>49.0</td>\n      <td>60.0</td>\n      <td>30.2603</td>\n      <td>27.0</td>\n      <td>8.0</td>\n      <td>1111.9569</td>\n      <td>0.1428</td>\n      <td>9.0365</td>\n      <td>30.0</td>\n      <td>...</td>\n      <td>19.0</td>\n      <td>17.0</td>\n      <td>7.0</td>\n      <td>63</td>\n      <td>63</td>\n      <td>63</td>\n      <td>81</td>\n      <td>80.0</td>\n      <td>20.0</td>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>35064</th>\n      <td>2022/7/18 2:32</td>\n      <td>49.0</td>\n      <td>60.0</td>\n      <td>30.2603</td>\n      <td>27.0</td>\n      <td>10.0</td>\n      <td>1680.4688</td>\n      <td>0.1425</td>\n      <td>9.0495</td>\n      <td>30.0</td>\n      <td>...</td>\n      <td>43.0</td>\n      <td>45.0</td>\n      <td>15.0</td>\n      <td>63</td>\n      <td>63</td>\n      <td>62</td>\n      <td>82</td>\n      <td>19.0</td>\n      <td>11.0</td>\n      <td>34.0</td>\n    </tr>\n    <tr>\n      <th>35065</th>\n      <td>2022/7/18 2:34</td>\n      <td>49.0</td>\n      <td>60.0</td>\n      <td>30.2603</td>\n      <td>27.0</td>\n      <td>8.0</td>\n      <td>1633.5309</td>\n      <td>0.1425</td>\n      <td>9.0419</td>\n      <td>30.0</td>\n      <td>...</td>\n      <td>73.0</td>\n      <td>73.0</td>\n      <td>37.0</td>\n      <td>62</td>\n      <td>63</td>\n      <td>62</td>\n      <td>82</td>\n      <td>22.0</td>\n      <td>10.0</td>\n      <td>34.0</td>\n    </tr>\n    <tr>\n      <th>35066</th>\n      <td>2022/7/18 2:36</td>\n      <td>49.0</td>\n      <td>60.0</td>\n      <td>30.2603</td>\n      <td>27.0</td>\n      <td>8.0</td>\n      <td>1247.8890</td>\n      <td>0.1425</td>\n      <td>9.0093</td>\n      <td>30.0</td>\n      <td>...</td>\n      <td>39.0</td>\n      <td>49.0</td>\n      <td>9.0</td>\n      <td>62</td>\n      <td>62</td>\n      <td>61</td>\n      <td>80</td>\n      <td>23.0</td>\n      <td>9.0</td>\n      <td>32.0</td>\n    </tr>\n    <tr>\n      <th>35067</th>\n      <td>2022/7/18 2:38</td>\n      <td>49.0</td>\n      <td>60.0</td>\n      <td>32.8130</td>\n      <td>27.0</td>\n      <td>35.0</td>\n      <td>998.9305</td>\n      <td>0.1425</td>\n      <td>9.0191</td>\n      <td>34.0</td>\n      <td>...</td>\n      <td>18.0</td>\n      <td>35.0</td>\n      <td>0.0</td>\n      <td>61</td>\n      <td>62</td>\n      <td>60</td>\n      <td>77</td>\n      <td>47.0</td>\n      <td>15.0</td>\n      <td>32.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>35068 rows × 165 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 删除分布不均衡的特征"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "train['test'] = 0\n",
    "test['test'] = 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35068\n",
      "66326.05 814.49\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's l1: 1509.31\ttraining's l2: 4.75368e+06\tvalid_1's l1: 1271.9\tvalid_1's l2: 2.72246e+06\n",
      "[400]\ttraining's l1: 1213.14\ttraining's l2: 3.22128e+06\tvalid_1's l1: 1233.02\tvalid_1's l2: 2.60666e+06\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's l1: 1249.56\ttraining's l2: 3.37592e+06\tvalid_1's l1: 1230.24\tvalid_1's l2: 2.59327e+06\n",
      "35068\n",
      "49464.13 719.71\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01, min_child_weight=1 will be ignored. Current value: min_sum_hessian_in_leaf=0.01\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\ttraining's l1: 1208.67\ttraining's l2: 3.0688e+06\tvalid_1's l1: 1129.71\tvalid_1's l2: 2.02808e+06\n",
      "[400]\ttraining's l1: 969.311\ttraining's l2: 2.11691e+06\tvalid_1's l1: 1022.9\tvalid_1's l2: 1.69109e+06\n",
      "[600]\ttraining's l1: 889.246\ttraining's l2: 1.8187e+06\tvalid_1's l1: 1003.4\tvalid_1's l2: 1.62658e+06\n",
      "[800]\ttraining's l1: 841.17\ttraining's l2: 1.64036e+06\tvalid_1's l1: 980.943\tvalid_1's l2: 1.56642e+06\n",
      "[1000]\ttraining's l1: 807.429\ttraining's l2: 1.51237e+06\tvalid_1's l1: 969.92\tvalid_1's l2: 1.53947e+06\n",
      "[1200]\ttraining's l1: 779.347\ttraining's l2: 1.41218e+06\tvalid_1's l1: 964.708\tvalid_1's l2: 1.52705e+06\n",
      "[1400]\ttraining's l1: 755.423\ttraining's l2: 1.32765e+06\tvalid_1's l1: 962.605\tvalid_1's l2: 1.5205e+06\n",
      "[1600]\ttraining's l1: 734.814\ttraining's l2: 1.25821e+06\tvalid_1's l1: 961.158\tvalid_1's l2: 1.51859e+06\n",
      "Early stopping, best iteration is:\n",
      "[1500]\ttraining's l1: 744.97\ttraining's l2: 1.29219e+06\tvalid_1's l1: 960.785\tvalid_1's l2: 1.51701e+06\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "score_list = []\n",
    "for label in labels:\n",
    "    train[label] = train[label].fillna(0)\n",
    "    tmp = train[~train[label].isna()].reset_index(drop=True).copy(deep=True)\n",
    "    print(len(tmp))\n",
    "    print(np.max(tmp[label]), np.min(tmp[label]))\n",
    "    test_size = 4000\n",
    "    X_train = tmp[features][:-test_size]\n",
    "    X_test = tmp[features][-test_size:]\n",
    "    y_train = tmp[label][:-test_size]\n",
    "    y_test = tmp[label][-test_size:]\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        boosting=\"gbdt\",\n",
    "        max_depth=4,\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=10000,\n",
    "        min_child_weight=1,\n",
    "        min_data_in_leaf=60,\n",
    "        subsample = 0.7,\n",
    "        feature_fraction=0.9,\n",
    "        bagging_seed=1,\n",
    "        reg_alpha=1,\n",
    "        reg_lambda=1,  # 此处不改了\n",
    "        min_sum_hessian_in_leaf=0.01,\n",
    "        random_state=1212\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], eval_metric=['mae'],\n",
    "          early_stopping_rounds=150, verbose=200)\n",
    "\n",
    "    model2 = lgb.LGBMRegressor(\n",
    "        boosting=\"gbdt\",\n",
    "        max_depth=4,\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=int(1.2*model.best_iteration_),\n",
    "        min_child_weight=1,\n",
    "        min_data_in_leaf=60,\n",
    "        subsample = 0.7,\n",
    "        feature_fraction=0.9,\n",
    "        bagging_seed=1,\n",
    "        reg_alpha=1,\n",
    "        reg_lambda=1,  # 此处不改了\n",
    "        min_sum_hessian_in_leaf=0.01,\n",
    "        random_state=1212\n",
    "    )\n",
    "    model2.fit(tmp[features], tmp[label])\n",
    "    score_list.append(np.sqrt(model.best_score_['valid_1']['l2']))\n",
    "    test[label] = model2.predict(test[features])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7032271676086042"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = np.mean(score_list)\n",
    "1000/(1+loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "test[['time'] + labels].to_csv(\"./res/base_line.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}