{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train_dataset.csv')\n",
    "test = pd.read_csv('./data/evaluation_public.csv')\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "\n",
    "data['isnull'] = data.iloc[:,1:].isnull().mean(axis = 1)\n",
    "data['isnull'] = data.iloc[:,1:].isnull().mean(axis = 1)\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "data['hour'] = data['time'].dt.hour\n",
    "data['minute'] = data['time'].dt.minute\n",
    "data['weekday'] = data['time'].dt.weekday\n",
    "data['ts'] = data['hour']*3600 + data['minute']*60 + data['time'].dt.second"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature len is 23\n"
     ]
    }
   ],
   "source": [
    "train = data.iloc[:140480].reset_index(drop = True)\n",
    "test = data.iloc[140480:].reset_index(drop = True)\n",
    "\n",
    "## 通过特征重要性、对抗验证、特征相关性，剔除了这7个特征，可能剔除错了也可能没剔除干净\n",
    "feas = [f for f in train.columns if f not in ['time', 'Label1', 'Label2','Label1_log','Label2_log','CS_LL',\n",
    "                                              'B_QY_ORP','JS_TN', 'CS_SW','MCCS_NH4','N_HYC_JS_DO','MCCS_NO3','JS_SW',\n",
    "                                             ]]\n",
    "print(f\"feature len is {len(feas)}\")\n",
    "for f in feas:\n",
    "    train[f] = train[f].fillna(method='ffill')\n",
    "train = train.dropna(subset=['Label1', 'Label2']).reset_index(drop=True)\n",
    "test['is_train'] = False\n",
    "train['is_train'] = True\n",
    "# data = pd.concat([train, test]).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JS_NH3', 'CS_NH3', 'CS_TN', 'JS_LL', 'JS_COD', 'CS_COD', 'B_HYC_NH4', 'B_HYC_XD', 'B_HYC_MLSS', 'B_HYC_JS_DO', 'B_HYC_DO', 'B_CS_MQ_SSLL', 'N_HYC_NH4', 'N_HYC_XD', 'N_HYC_MLSS', 'N_HYC_DO', 'N_CS_MQ_SSLL', 'N_QY_ORP', 'isnull', 'hour', 'minute', 'weekday', 'ts']\n"
     ]
    }
   ],
   "source": [
    "print(feas)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "outputs": [],
   "source": [
    "# df_list = []\n",
    "# i = 0\n",
    "# add_featuers = []\n",
    "# length = 0\n",
    "# for f in ['JS_NH3', 'CS_NH3', 'CS_TN', 'JS_LL', 'JS_COD', 'CS_COD', 'B_HYC_NH4', 'B_HYC_XD', 'B_HYC_MLSS', 'B_HYC_JS_DO', 'B_HYC_DO', 'B_CS_MQ_SSLL',\n",
    "#           'N_HYC_NH4', 'N_HYC_XD', 'N_HYC_MLSS', 'N_HYC_DO', 'N_CS_MQ_SSLL', 'N_QY_ORP']:\n",
    "#     for r in [3,5,7,10]:\n",
    "#         train_rolling = data[f].rolling(window=r, center=True)\n",
    "#         f_mean_name = 'rolling{}_{}_mean'.format(r,f)\n",
    "#         f_max_name = 'rolling{}_{}_max'.format(r,f)\n",
    "#         f_min_name = 'rolling{}_{}_min'.format(r,f)\n",
    "#         f_std_name = 'rolling{}_{}_std'.format(r,f)\n",
    "#         data[f_mean_name] = train_rolling.mean().fillna(0).values\n",
    "#         data[f_max_name] = train_rolling.max().fillna(0).values\n",
    "#         data[f_min_name] = train_rolling.min().fillna(0).values\n",
    "#         data[f_std_name] = train_rolling.std().fillna(0).values\n",
    "#         data[f'{f}_{f_mean_name}_cha'] = data[f] - data[f_mean_name]\n",
    "#         data[f'{f}_{f_max_name}_cha'] = data[f] - data[f_max_name]\n",
    "#         data[f'{f}_{f_min_name}_cha'] = data[f] - data[f_min_name]\n",
    "#         if i == 0:\n",
    "#             add_featuers.append(f_mean_name)\n",
    "#             add_featuers.append(f_max_name)\n",
    "#             add_featuers.append(f_min_name)\n",
    "#             add_featuers.append(f_std_name)\n",
    "#             add_featuers.append(f'{f}_{f_mean_name}_cha')\n",
    "#             add_featuers.append(f'{f}_{f_max_name}_cha')\n",
    "#             add_featuers.append(f'{f}_{f_min_name}_cha')\n",
    "# feas.extend(add_featuers)\n",
    "# train = data[data['is_train']].reset_index(drop=True)\n",
    "# test = data[~data['is_train']].reset_index(drop=True)\n",
    "\n",
    "train['Label1'] = np.log1p(train['Label1'])\n",
    "train['Label2'] = np.log1p(train['Label2'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "outputs": [
    {
     "data": {
      "text/plain": "35068"
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def train_model(data_, test_, y_, folds_,features):\n",
    "    oof_preds = np.zeros(data_.shape[0])\n",
    "    sub_preds = np.zeros(test_.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = features\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds_.split(data_)):\n",
    "        trn_x, trn_y = data_[feats].iloc[trn_idx], y_.iloc[trn_idx]\n",
    "        val_x, val_y = data_[feats].iloc[val_idx], y_.iloc[val_idx]\n",
    "        clf = lgb.LGBMRegressor(\n",
    "                # boosting=\"gbdt\",\n",
    "                num_leaves=2**4,\n",
    "                learning_rate=0.03,\n",
    "                n_estimators=40000,\n",
    "                min_child_weight=1,\n",
    "                min_data_in_leaf=10,\n",
    "                subsample = 0.7,\n",
    "                feature_fraction=0.6,\n",
    "                bagging_seed=1,\n",
    "                reg_alpha=1,\n",
    "                reg_lambda=1,  # 此处不改了\n",
    "                min_sum_hessian_in_leaf=0.01,\n",
    "                random_state=1212\n",
    "            )\n",
    "\n",
    "        clf.fit(trn_x, trn_y,\n",
    "                eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "                eval_metric='mse', verbose=500, early_stopping_rounds=40  # 30\n",
    "                )\n",
    "\n",
    "        oof_preds[val_idx] = clf.predict(val_x, num_iteration=clf.best_iteration_)\n",
    "        sub_preds += clf.predict(test_[feats], num_iteration=clf.best_iteration_) / folds_.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        print('Fold %2d rmse : %.6f' % (n_fold + 1, np.sqrt(mean_squared_error(np.expm1(val_y), np.expm1(oof_preds[val_idx])))))\n",
    "        del clf, trn_x, trn_y, val_x, val_y\n",
    "        gc.collect()\n",
    "    sv_score = np.sqrt(mean_squared_error(np.expm1(y_), np.expm1(oof_preds)))\n",
    "    feature_importance_df = feature_importance_df.groupby(['feature'])[['importance']].mean().reset_index(drop=False)\n",
    "    feature_importance_df.columns = ['feature', 'importance']\n",
    "    print('Full rmse score %.6f' % sv_score)\n",
    "\n",
    "    test_['isDefault'] = np.expm1(sub_preds)\n",
    "\n",
    "    return oof_preds, test_['isDefault'], sv_score, feature_importance_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01, min_child_weight=1 will be ignored. Current value: min_sum_hessian_in_leaf=0.01\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[500]\ttraining's l2: 0.0101742\tvalid_1's l2: 0.0142672\n",
      "[1000]\ttraining's l2: 0.00758818\tvalid_1's l2: 0.0130543\n",
      "[1500]\ttraining's l2: 0.00625884\tvalid_1's l2: 0.0124427\n",
      "[2000]\ttraining's l2: 0.00534805\tvalid_1's l2: 0.0120289\n",
      "[2500]\ttraining's l2: 0.00470987\tvalid_1's l2: 0.0117421\n",
      "[3000]\ttraining's l2: 0.00423333\tvalid_1's l2: 0.0115188\n",
      "[3500]\ttraining's l2: 0.00384468\tvalid_1's l2: 0.0113664\n",
      "[4000]\ttraining's l2: 0.00354411\tvalid_1's l2: 0.0112476\n",
      "[4500]\ttraining's l2: 0.00328021\tvalid_1's l2: 0.0111536\n",
      "Early stopping, best iteration is:\n",
      "[4958]\ttraining's l2: 0.00306932\tvalid_1's l2: 0.0110642\n",
      "Fold  1 rmse : 1481.765168\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01, min_child_weight=1 will be ignored. Current value: min_sum_hessian_in_leaf=0.01\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[500]\ttraining's l2: 0.0104514\tvalid_1's l2: 0.012237\n",
      "[1000]\ttraining's l2: 0.00782866\tvalid_1's l2: 0.0107745\n",
      "[1500]\ttraining's l2: 0.00645803\tvalid_1's l2: 0.0100339\n",
      "[2000]\ttraining's l2: 0.00554243\tvalid_1's l2: 0.00955589\n",
      "[2500]\ttraining's l2: 0.00486231\tvalid_1's l2: 0.00921331\n",
      "[3000]\ttraining's l2: 0.00434989\tvalid_1's l2: 0.00900011\n",
      "[3500]\ttraining's l2: 0.00394208\tvalid_1's l2: 0.00882756\n",
      "[4000]\ttraining's l2: 0.00361426\tvalid_1's l2: 0.0086808\n",
      "[4500]\ttraining's l2: 0.00334213\tvalid_1's l2: 0.00857862\n",
      "[5000]\ttraining's l2: 0.00310979\tvalid_1's l2: 0.00847734\n",
      "[5500]\ttraining's l2: 0.00290459\tvalid_1's l2: 0.00839278\n",
      "[6000]\ttraining's l2: 0.00272301\tvalid_1's l2: 0.00833678\n",
      "[6500]\ttraining's l2: 0.00256769\tvalid_1's l2: 0.00828123\n",
      "[7000]\ttraining's l2: 0.00243045\tvalid_1's l2: 0.00823615\n",
      "Early stopping, best iteration is:\n",
      "[7040]\ttraining's l2: 0.00242034\tvalid_1's l2: 0.00823297\n",
      "Fold  2 rmse : 1325.612355\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01, min_child_weight=1 will be ignored. Current value: min_sum_hessian_in_leaf=0.01\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[500]\ttraining's l2: 0.0101071\tvalid_1's l2: 0.0147636\n",
      "[1000]\ttraining's l2: 0.00763128\tvalid_1's l2: 0.0131983\n",
      "[1500]\ttraining's l2: 0.00632793\tvalid_1's l2: 0.0124394\n",
      "[2000]\ttraining's l2: 0.00548871\tvalid_1's l2: 0.0119274\n",
      "[2500]\ttraining's l2: 0.00488329\tvalid_1's l2: 0.0115697\n",
      "[3000]\ttraining's l2: 0.00438154\tvalid_1's l2: 0.0112979\n",
      "[3500]\ttraining's l2: 0.00398356\tvalid_1's l2: 0.0111104\n",
      "[4000]\ttraining's l2: 0.0036427\tvalid_1's l2: 0.0109396\n",
      "[4500]\ttraining's l2: 0.00336115\tvalid_1's l2: 0.0107714\n",
      "[5000]\ttraining's l2: 0.00313017\tvalid_1's l2: 0.0106613\n",
      "[5500]\ttraining's l2: 0.00291647\tvalid_1's l2: 0.0105759\n",
      "[6000]\ttraining's l2: 0.00273465\tvalid_1's l2: 0.0105044\n",
      "[6500]\ttraining's l2: 0.00257187\tvalid_1's l2: 0.010422\n",
      "[7000]\ttraining's l2: 0.00242816\tvalid_1's l2: 0.010348\n",
      "[7500]\ttraining's l2: 0.00229714\tvalid_1's l2: 0.0102793\n",
      "[8000]\ttraining's l2: 0.00218547\tvalid_1's l2: 0.0102372\n",
      "[8500]\ttraining's l2: 0.00208726\tvalid_1's l2: 0.0101983\n",
      "Early stopping, best iteration is:\n",
      "[8503]\ttraining's l2: 0.00208661\tvalid_1's l2: 0.0101976\n",
      "Fold  3 rmse : 1329.731372\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01, min_child_weight=1 will be ignored. Current value: min_sum_hessian_in_leaf=0.01\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[500]\ttraining's l2: 0.0107242\tvalid_1's l2: 0.0102018\n",
      "[1000]\ttraining's l2: 0.00804521\tvalid_1's l2: 0.00888203\n",
      "[1500]\ttraining's l2: 0.00663093\tvalid_1's l2: 0.00828414\n",
      "[2000]\ttraining's l2: 0.00565226\tvalid_1's l2: 0.00788751\n",
      "[2500]\ttraining's l2: 0.00496352\tvalid_1's l2: 0.00763004\n",
      "[3000]\ttraining's l2: 0.00444412\tvalid_1's l2: 0.00741012\n",
      "[3500]\ttraining's l2: 0.00402114\tvalid_1's l2: 0.00726012\n",
      "[4000]\ttraining's l2: 0.00367926\tvalid_1's l2: 0.0071272\n",
      "[4500]\ttraining's l2: 0.00338631\tvalid_1's l2: 0.00703115\n",
      "[5000]\ttraining's l2: 0.00315239\tvalid_1's l2: 0.00694456\n",
      "[5500]\ttraining's l2: 0.00294369\tvalid_1's l2: 0.00686991\n",
      "[6000]\ttraining's l2: 0.00276602\tvalid_1's l2: 0.00679692\n",
      "[6500]\ttraining's l2: 0.0026025\tvalid_1's l2: 0.00672767\n",
      "[7000]\ttraining's l2: 0.00245902\tvalid_1's l2: 0.0066943\n",
      "[7500]\ttraining's l2: 0.00233147\tvalid_1's l2: 0.00665724\n",
      "[8000]\ttraining's l2: 0.00222071\tvalid_1's l2: 0.00662287\n",
      "Early stopping, best iteration is:\n",
      "[8315]\ttraining's l2: 0.00215423\tvalid_1's l2: 0.00659979\n",
      "Fold  4 rmse : 1319.524753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01, min_child_weight=1 will be ignored. Current value: min_sum_hessian_in_leaf=0.01\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[500]\ttraining's l2: 0.0100613\tvalid_1's l2: 0.014745\n",
      "[1000]\ttraining's l2: 0.00754894\tvalid_1's l2: 0.0134669\n",
      "[1500]\ttraining's l2: 0.00624909\tvalid_1's l2: 0.012781\n",
      "[2000]\ttraining's l2: 0.00534679\tvalid_1's l2: 0.0123334\n",
      "[2500]\ttraining's l2: 0.00472027\tvalid_1's l2: 0.0120108\n",
      "[3000]\ttraining's l2: 0.00423961\tvalid_1's l2: 0.0117924\n",
      "[3500]\ttraining's l2: 0.00382982\tvalid_1's l2: 0.0116048\n",
      "Early stopping, best iteration is:\n",
      "[3751]\ttraining's l2: 0.00365828\tvalid_1's l2: 0.0115437\n",
      "Fold  5 rmse : 1503.896927\n",
      "Full rmse score 1394.553479\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01, min_child_weight=1 will be ignored. Current value: min_sum_hessian_in_leaf=0.01\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[500]\ttraining's l2: 0.00951332\tvalid_1's l2: 0.0137966\n",
      "[1000]\ttraining's l2: 0.00726858\tvalid_1's l2: 0.012716\n",
      "[1500]\ttraining's l2: 0.0060405\tvalid_1's l2: 0.0120851\n",
      "[2000]\ttraining's l2: 0.00522602\tvalid_1's l2: 0.0117066\n",
      "[2500]\ttraining's l2: 0.00463127\tvalid_1's l2: 0.0115189\n",
      "[3000]\ttraining's l2: 0.00417737\tvalid_1's l2: 0.0113271\n",
      "[3500]\ttraining's l2: 0.00381428\tvalid_1's l2: 0.0111931\n",
      "[4000]\ttraining's l2: 0.00351024\tvalid_1's l2: 0.0110633\n",
      "[4500]\ttraining's l2: 0.00325641\tvalid_1's l2: 0.0109761\n",
      "[5000]\ttraining's l2: 0.00302991\tvalid_1's l2: 0.0108894\n",
      "[5500]\ttraining's l2: 0.00283555\tvalid_1's l2: 0.0108208\n",
      "[6000]\ttraining's l2: 0.00265722\tvalid_1's l2: 0.010754\n",
      "[6500]\ttraining's l2: 0.00251088\tvalid_1's l2: 0.0107048\n",
      "[7000]\ttraining's l2: 0.0023703\tvalid_1's l2: 0.0106621\n",
      "[7500]\ttraining's l2: 0.00224614\tvalid_1's l2: 0.010615\n",
      "[8000]\ttraining's l2: 0.00213408\tvalid_1's l2: 0.0105698\n",
      "[8500]\ttraining's l2: 0.00203529\tvalid_1's l2: 0.0105425\n",
      "[9000]\ttraining's l2: 0.00194494\tvalid_1's l2: 0.0105141\n",
      "[9500]\ttraining's l2: 0.00185939\tvalid_1's l2: 0.0104843\n",
      "Early stopping, best iteration is:\n",
      "[9522]\ttraining's l2: 0.00185568\tvalid_1's l2: 0.0104832\n",
      "Fold  1 rmse : 1189.425698\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01, min_child_weight=1 will be ignored. Current value: min_sum_hessian_in_leaf=0.01\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[500]\ttraining's l2: 0.00978475\tvalid_1's l2: 0.0114901\n",
      "[1000]\ttraining's l2: 0.00752494\tvalid_1's l2: 0.0103505\n",
      "[1500]\ttraining's l2: 0.00618496\tvalid_1's l2: 0.00972946\n",
      "[2000]\ttraining's l2: 0.00535036\tvalid_1's l2: 0.00931844\n",
      "[2500]\ttraining's l2: 0.00473899\tvalid_1's l2: 0.00908354\n",
      "Early stopping, best iteration is:\n",
      "[2489]\ttraining's l2: 0.0047562\tvalid_1's l2: 0.00908069\n",
      "Fold  2 rmse : 1182.541753\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01, min_child_weight=1 will be ignored. Current value: min_sum_hessian_in_leaf=0.01\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[500]\ttraining's l2: 0.00962471\tvalid_1's l2: 0.0137644\n",
      "[1000]\ttraining's l2: 0.00743929\tvalid_1's l2: 0.0126203\n",
      "[1500]\ttraining's l2: 0.006162\tvalid_1's l2: 0.011896\n",
      "[2000]\ttraining's l2: 0.00528219\tvalid_1's l2: 0.0114767\n",
      "[2500]\ttraining's l2: 0.00470992\tvalid_1's l2: 0.0111935\n",
      "[3000]\ttraining's l2: 0.004264\tvalid_1's l2: 0.0109687\n",
      "[3500]\ttraining's l2: 0.00389\tvalid_1's l2: 0.0107976\n",
      "Early stopping, best iteration is:\n",
      "[3570]\ttraining's l2: 0.00383435\tvalid_1's l2: 0.0107682\n",
      "Fold  3 rmse : 1138.523048\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01, min_child_weight=1 will be ignored. Current value: min_sum_hessian_in_leaf=0.01\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[500]\ttraining's l2: 0.0100422\tvalid_1's l2: 0.00973825\n",
      "[1000]\ttraining's l2: 0.00765387\tvalid_1's l2: 0.00868614\n",
      "[1500]\ttraining's l2: 0.00638693\tvalid_1's l2: 0.00820614\n",
      "[2000]\ttraining's l2: 0.00549712\tvalid_1's l2: 0.00788324\n",
      "[2500]\ttraining's l2: 0.00482877\tvalid_1's l2: 0.00764189\n",
      "[3000]\ttraining's l2: 0.0043595\tvalid_1's l2: 0.00746665\n",
      "[3500]\ttraining's l2: 0.00395026\tvalid_1's l2: 0.00734254\n",
      "[4000]\ttraining's l2: 0.00361987\tvalid_1's l2: 0.00722553\n",
      "[4500]\ttraining's l2: 0.00336052\tvalid_1's l2: 0.00711851\n",
      "[5000]\ttraining's l2: 0.0031282\tvalid_1's l2: 0.00704177\n",
      "[5500]\ttraining's l2: 0.0029231\tvalid_1's l2: 0.00697702\n",
      "[6000]\ttraining's l2: 0.00274773\tvalid_1's l2: 0.00691916\n",
      "Early stopping, best iteration is:\n",
      "[6283]\ttraining's l2: 0.00265404\tvalid_1's l2: 0.00688423\n",
      "Fold  4 rmse : 1124.297266\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.01, min_child_weight=1 will be ignored. Current value: min_sum_hessian_in_leaf=0.01\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[500]\ttraining's l2: 0.00944911\tvalid_1's l2: 0.013722\n",
      "[1000]\ttraining's l2: 0.00727828\tvalid_1's l2: 0.0126837\n",
      "[1500]\ttraining's l2: 0.00602083\tvalid_1's l2: 0.0121575\n",
      "[2000]\ttraining's l2: 0.00517638\tvalid_1's l2: 0.0117916\n",
      "[2500]\ttraining's l2: 0.0045975\tvalid_1's l2: 0.0115472\n",
      "[3000]\ttraining's l2: 0.00415461\tvalid_1's l2: 0.011324\n",
      "[3500]\ttraining's l2: 0.00378487\tvalid_1's l2: 0.0111904\n",
      "[4000]\ttraining's l2: 0.00348919\tvalid_1's l2: 0.0110947\n",
      "[4500]\ttraining's l2: 0.0032352\tvalid_1's l2: 0.0110061\n",
      "[5000]\ttraining's l2: 0.00301415\tvalid_1's l2: 0.0109447\n",
      "Early stopping, best iteration is:\n",
      "[5169]\ttraining's l2: 0.0029463\tvalid_1's l2: 0.0109284\n",
      "Fold  5 rmse : 1202.553366\n",
      "Full rmse score 1167.865975\n",
      "last_score = 0.779903613927383\n"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=2222)\n",
    "scores = []\n",
    "feature_score_list = []\n",
    "for label in ['Label1', 'Label2']:\n",
    "    _, test[label], score, feature_score = train_model(train, test, train[label], kf, feas)\n",
    "    scores.append(score)\n",
    "    feature_score_list.append(feature_score)\n",
    "last_score = 1/(1+(scores[0]+scores[1])/2)*1000\n",
    "print(f\"last_score = {last_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "outputs": [],
   "source": [
    "# print(f\"last_score = {last_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 由于线上线下分数差别太大，查看是不是部分特征分布抬不均衡"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "outputs": [],
   "source": [
    "# train['test'] = 0\n",
    "# test['test'] = 1\n",
    "# all_data_v2 = pd.concat([train, test]).reset_index(drop=True)\n",
    "# print(len(all_data_v2))\n",
    "#\n",
    "# X_train, X_test, y_train, y_test  = train_test_split(all_data_v2[test_feature].copy(deep=True), all_data_v2['test'].copy(deep=True), test_size=0.2)\n",
    "# fortest_model = lgb.LGBMClassifier(\n",
    "#         num_leaves=2**4,\n",
    "#         learning_rate=0.03,\n",
    "#         n_estimators=300,\n",
    "#         min_child_weight=1,\n",
    "#         min_data_in_leaf=10,\n",
    "#         subsample = 0.7,\n",
    "#         feature_fraction=0.4,\n",
    "#         bagging_seed=1,\n",
    "#         reg_alpha=1,\n",
    "#         reg_lambda=1,  # 此处不改了\n",
    "#         min_sum_hessian_in_leaf=0.01,\n",
    "#         random_state=1212)\n",
    "#\n",
    "# fortest_model.fit(X_train, y_train,\n",
    "#                 eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "#                 eval_metric='auc', verbose=100, early_stopping_rounds=40  # 30\n",
    "#                 )\n",
    "# test_feture = pd.DataFrame()\n",
    "# test_feture['feature'] = test_feature\n",
    "# test_feture['score'] = fortest_model.feature_importances_\n",
    "# test_feture.sort_values(by=['score'], ascending=False, inplace=True, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "outputs": [],
   "source": [
    "# test_feture # rolling3_CS_NH3_std  rolling5_CS_NH3_std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "outputs": [],
   "source": [
    "# xxxx = list(test_feture['feature'][-150:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "outputs": [],
   "source": [
    "# folds = 5\n",
    "# kf = KFold(n_splits=folds, shuffle=True, random_state=2222)\n",
    "# scores = []\n",
    "# for label in ['Label1', 'Label2']:\n",
    "#     _, test[label], score, feature_score = train_model(train, test, train[label], kf, test_feture['feature'].values[-150:])\n",
    "#     scores.append(score)\n",
    "# last_score = 1000/(1+(scores[0]+scores[1])/2)\n",
    "# print(f\"last_score = {last_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sample_submission = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "sample_submission['Label1'] = test['Label1']\n",
    "sample_submission['Label2'] = test['Label2']\n",
    "sample_submission.to_csv('./data/base_line.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 437,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rolling7_B_CS_MQ_SSLL_min', 'rolling7_B_CS_MQ_SSLL_max', 'JS_LL_rolling10_JS_LL_max_cha', 'N_HYC_DO_rolling5_N_HYC_DO_min_cha', 'N_CS_MQ_SSLL']\n"
     ]
    }
   ],
   "source": [
    "print(list(test_feture['feature']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}