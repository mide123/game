{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/train_dataset.csv\")\n",
    "\n",
    "data['is_test'] = False\n",
    "evaluation = pd.read_csv(\"./data/evaluation_public.csv\")\n",
    "evaluation['is_test'] = True\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "\n",
    "all_data = pd.concat([data, evaluation]).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 特征处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "all_data['date'] = pd.to_datetime(all_data['time'])\n",
    "all_data['hour'] = all_data['date'].dt.hour\n",
    "all_data['year'] = all_data['date'].dt.year\n",
    "all_data['month'] = all_data['date'].dt.month\n",
    "all_data['minute'] = all_data['date'].dt.minute\n",
    "all_data['weekday'] = all_data['date'].dt.weekday\n",
    "all_data['day'] = all_data['date'].dt.day\n",
    "all_data['hour'] = all_data['date'].dt.hour\n",
    "all_data['ts'] = all_data['hour']*3600 + all_data['minute']*60 + all_data['date'].dt.second"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "features = [ 'JS_NH3', 'CS_NH3', 'JS_TN', 'CS_TN', 'JS_LL', 'CS_LL', 'MCCS_NH4', 'MCCS_NO3', 'JS_COD', 'CS_COD', 'JS_SW', 'CS_SW', 'B_HYC_NH4', 'B_HYC_XD', 'B_HYC_MLSS', 'B_HYC_JS_DO', 'B_HYC_DO', 'B_CS_MQ_SSLL', 'B_QY_ORP', 'N_HYC_NH4', 'N_HYC_XD', 'N_HYC_MLSS', 'N_HYC_JS_DO', 'N_HYC_DO', 'N_CS_MQ_SSLL', 'N_QY_ORP','weekday','hour', 'ts']\n",
    "features = [f for f in features if f not in ['time', 'Label1', 'Label2','Label1_log','Label2_log','CS_LL',\n",
    "                                             'CS_NH3', 'JS_SW'\n",
    "                                               # 'B_QY_ORP','JS_TN', 'CS_SW','MCCS_NH4','N_HYC_JS_DO','MCCS_NO3','JS_SW',\n",
    "                                             ]]\n",
    "\n",
    "labels = ['Label1', 'Label2']\n",
    "train = all_data[~all_data['is_test']].copy(deep=True)\n",
    "test = all_data[all_data['is_test']].copy(deep=True)\n",
    "# train = train.dropna(subset=['Label1', 'Label2']).reset_index(drop=True)\n",
    "test['is_train'] = False\n",
    "train['is_train'] = True\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "del all_data\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 通过训练找出在训练集和测试集中差别很大的样本"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train['is_test'] = 0\n",
    "test['is_test'] = 1\n",
    "data_v2 = pd.concat([train, test]).reset_index(drop=True)\n",
    "for f in features:\n",
    "    if f not in ['weekday','hour', 'ts']:\n",
    "        q = len(data_v2[f].drop_duplicates())\n",
    "        data_v2[f] = pd.qcut(data_v2[f], q=int(q/10), labels=False, duplicates=\"drop\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS_NH3\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.505011\ttraining's binary_logloss: 0.244544\tvalid_1's auc: 0.487318\tvalid_1's binary_logloss: 0.243667\n",
      "\n",
      "\n",
      "CS_NH3\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.504178\ttraining's binary_logloss: 0.244522\tvalid_1's auc: 0.490698\tvalid_1's binary_logloss: 0.243754\n",
      "\n",
      "\n",
      "JS_TN\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.502673\ttraining's binary_logloss: 0.244851\tvalid_1's auc: 0.496647\tvalid_1's binary_logloss: 0.242439\n",
      "\n",
      "\n",
      "CS_TN\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.50293\ttraining's binary_logloss: 0.245727\tvalid_1's auc: 0.495456\tvalid_1's binary_logloss: 0.238944\n",
      "\n",
      "\n",
      "JS_LL\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.504035\ttraining's binary_logloss: 0.246143\tvalid_1's auc: 0.490849\tvalid_1's binary_logloss: 0.237289\n",
      "\n",
      "\n",
      "MCCS_NH4\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.502524\ttraining's binary_logloss: 0.243885\tvalid_1's auc: 0.49002\tvalid_1's binary_logloss: 0.246303\n",
      "\n",
      "\n",
      "MCCS_NO3\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.502685\ttraining's binary_logloss: 0.246208\tvalid_1's auc: 0.493742\tvalid_1's binary_logloss: 0.237028\n",
      "\n",
      "\n",
      "JS_COD\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.506981\ttraining's binary_logloss: 0.242851\tvalid_1's auc: 0.477942\tvalid_1's binary_logloss: 0.250451\n",
      "\n",
      "\n",
      "CS_COD\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.503076\ttraining's binary_logloss: 0.244039\tvalid_1's auc: 0.495135\tvalid_1's binary_logloss: 0.245687\n",
      "\n",
      "\n",
      "JS_SW\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.50555\ttraining's binary_logloss: 0.243621\tvalid_1's auc: 0.480637\tvalid_1's binary_logloss: 0.24736\n",
      "\n",
      "\n",
      "CS_SW\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.502812\ttraining's binary_logloss: 0.244281\tvalid_1's auc: 0.493698\tvalid_1's binary_logloss: 0.24472\n",
      "\n",
      "\n",
      "B_HYC_NH4\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.504514\ttraining's binary_logloss: 0.243225\tvalid_1's auc: 0.482529\tvalid_1's binary_logloss: 0.248948\n",
      "\n",
      "\n",
      "B_HYC_XD\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.502878\ttraining's binary_logloss: 0.243797\tvalid_1's auc: 0.4959\tvalid_1's binary_logloss: 0.246655\n",
      "\n",
      "\n",
      "B_HYC_MLSS\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.504369\ttraining's binary_logloss: 0.245333\tvalid_1's auc: 0.489689\tvalid_1's binary_logloss: 0.240515\n",
      "\n",
      "\n",
      "B_HYC_JS_DO\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.504211\ttraining's binary_logloss: 0.243907\tvalid_1's auc: 0.488307\tvalid_1's binary_logloss: 0.246215\n",
      "\n",
      "\n",
      "B_HYC_DO\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.504761\ttraining's binary_logloss: 0.243665\tvalid_1's auc: 0.486132\tvalid_1's binary_logloss: 0.247184\n",
      "\n",
      "\n",
      "B_CS_MQ_SSLL\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.503938\ttraining's binary_logloss: 0.244895\tvalid_1's auc: 0.491442\tvalid_1's binary_logloss: 0.242264\n",
      "\n",
      "\n",
      "B_QY_ORP\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.503232\ttraining's binary_logloss: 0.245267\tvalid_1's auc: 0.494265\tvalid_1's binary_logloss: 0.240777\n",
      "\n",
      "\n",
      "N_HYC_NH4\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.504649\ttraining's binary_logloss: 0.243577\tvalid_1's auc: 0.489086\tvalid_1's binary_logloss: 0.247536\n",
      "\n",
      "\n",
      "N_HYC_XD\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.502694\ttraining's binary_logloss: 0.244149\tvalid_1's auc: 0.494176\tvalid_1's binary_logloss: 0.245247\n",
      "\n",
      "\n",
      "N_HYC_MLSS\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.505352\ttraining's binary_logloss: 0.243973\tvalid_1's auc: 0.486152\tvalid_1's binary_logloss: 0.245951\n",
      "\n",
      "\n",
      "N_HYC_JS_DO\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.503493\ttraining's binary_logloss: 0.245136\tvalid_1's auc: 0.483179\tvalid_1's binary_logloss: 0.241302\n",
      "\n",
      "\n",
      "N_HYC_DO\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.50349\ttraining's binary_logloss: 0.242807\tvalid_1's auc: 0.493742\tvalid_1's binary_logloss: 0.250628\n",
      "\n",
      "\n",
      "N_CS_MQ_SSLL\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.503297\ttraining's binary_logloss: 0.244719\tvalid_1's auc: 0.489243\tvalid_1's binary_logloss: 0.242965\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "# N_HYC_NH4\n",
    "for f in [ 'JS_NH3', 'CS_NH3', 'JS_TN', 'CS_TN', 'JS_LL', 'MCCS_NH4', 'MCCS_NO3', 'JS_COD', 'CS_COD', 'JS_SW', 'CS_SW', 'B_HYC_NH4', 'B_HYC_XD', 'B_HYC_MLSS', 'B_HYC_JS_DO', 'B_HYC_DO', 'B_CS_MQ_SSLL', 'B_QY_ORP', 'N_HYC_NH4', 'N_HYC_XD', 'N_HYC_MLSS', 'N_HYC_JS_DO', 'N_HYC_DO', 'N_CS_MQ_SSLL']:\n",
    "    features_filter = ['ts', 'weekday', f]\n",
    "    print(f)\n",
    "    X_train, X_test, y_train, y_test  = train_test_split(data_v2[features_filter], data_v2['is_test'], test_size=0.2)\n",
    "    model = lgb.LGBMClassifier(\n",
    "            boosting=\"gbdt\",\n",
    "            max_depth=4,\n",
    "            learning_rate=0.005,\n",
    "            n_estimators=500,\n",
    "            min_child_weight=1,\n",
    "            min_data_in_leaf=60,\n",
    "            subsample = 0.7,\n",
    "            feature_fraction=0.4,\n",
    "            bagging_seed=1,\n",
    "            reg_alpha=0.11,\n",
    "            reg_lambda=0.1,  # 此处不改了\n",
    "            min_sum_hessian_in_leaf=0.01,\n",
    "            random_state=1212\n",
    "        )\n",
    "    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], eval_metric=['auc'],\n",
    "              early_stopping_rounds=20, verbose=200)\n",
    "    print(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}