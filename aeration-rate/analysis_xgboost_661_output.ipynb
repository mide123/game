{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/train_dataset.csv\")\n",
    "\n",
    "data['is_train'] = True\n",
    "evaluation = pd.read_csv(\"./data/evaluation_public.csv\")\n",
    "evaluation['is_train'] = False\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "\n",
    "data = pd.concat([data, evaluation]).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 特征处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data['time'])\n",
    "data['hour'] = data['date'].dt.hour\n",
    "data['year'] = data['date'].dt.year\n",
    "data['month'] = data['date'].dt.month\n",
    "data['minute'] = data['date'].dt.minute\n",
    "data['weekday'] = data['date'].dt.weekday\n",
    "data['day'] = data['date'].dt.day\n",
    "data['hour'] = data['date'].dt.hour\n",
    "# data['ts'] = data['hour']*3600 + data['minute']*60 + data['date'].dt.second\n",
    "data['ts'] = data['hour']*60 + data['minute']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import gc\n",
    "features = [ 'JS_NH3', 'CS_NH3', 'JS_TN', 'CS_TN', 'JS_LL', 'CS_LL', 'MCCS_NH4', 'MCCS_NO3', 'JS_COD', 'CS_COD', 'JS_SW', 'CS_SW', 'B_HYC_NH4', 'B_HYC_XD', 'B_HYC_MLSS', 'B_HYC_JS_DO', 'B_HYC_DO', 'B_CS_MQ_SSLL', 'B_QY_ORP', 'N_HYC_NH4', 'N_HYC_XD', 'N_HYC_MLSS', 'N_HYC_JS_DO', 'N_HYC_DO', 'N_CS_MQ_SSLL', 'N_QY_ORP','weekday','hour', 'ts']\n",
    "\n",
    "filter_set = {'time', 'Label1', 'Label2','CS_LL','CS_NH3', 'JS_SW', 'B_QY_ORP'}\n",
    "features = [f for f in features if f not in filter_set] #\n",
    "for f in features:\n",
    "    data[f] = data[f].fillna(method='ffill')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 提取特征的diff值"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df_list = []\n",
    "i = 0\n",
    "add_featuers = []\n",
    "length = 0\n",
    "# JS_TN, MCCS_NO3,MCCS_NH4,'B_QY_ORP'\n",
    "filter_set = {'weekday', 'hour', 'ts', 'JS_TN', 'CS_SW', 'MCCS_NH4', 'N_HYC_JS_DO', 'MCCS_NO3'}\n",
    "for f in features:\n",
    "    if f in filter_set: continue\n",
    "    for r in [15]:\n",
    "        train_rolling = data[f].rolling(window=r, center=False)\n",
    "        f_mean_name = 'rolling{}_{}_mean'.format(r,f)\n",
    "        f_max_name = 'rolling{}_{}_max'.format(r,f)\n",
    "        f_min_name = 'rolling{}_{}_min'.format(r,f)\n",
    "        f_std_name = 'rolling{}_{}_std'.format(r,f)\n",
    "        f_corr_name = 'rolling{}_{}_corr'.format(r,f)\n",
    "        f_cov_name = 'rolling{}_{}_cov'.format(r,f)\n",
    "        f_skew_name = 'rolling{}_{}_skew'.format(r,f)\n",
    "        f_kurt_name = 'rolling{}_{}_kurt'.format(r,f)\n",
    "        data[f_mean_name] = train_rolling.mean().fillna(0).values\n",
    "        data[f_max_name] = train_rolling.max().fillna(0).values\n",
    "        data[f_min_name] = train_rolling.min().fillna(0).values\n",
    "        data[f_std_name] = train_rolling.std().fillna(0).values\n",
    "        data[f_corr_name] = train_rolling.corr().fillna(0).values\n",
    "        data[f_skew_name] = train_rolling.skew().fillna(0).values\n",
    "\n",
    "        data[f'{f}_{f_mean_name}_cha'] = data[f] - data[f_mean_name]\n",
    "        data[f'{f}_{f_max_name}_cha'] = data[f] - data[f_max_name]\n",
    "        data[f'{f}_{f_min_name}_cha'] = data[f] - data[f_min_name]\n",
    "\n",
    "        data[f'{f}_{f_min_name}_radio'] = data[f'{f}_{f_mean_name}_cha']/data[f]\n",
    "        data[f'{f}_{f_max_name}_radio'] = data[f'{f}_{f_max_name}_cha']/data[f]\n",
    "        data[f'{f}_{f_mean_name}_radio'] = data[f'{f}_{f_min_name}_cha']/data[f]\n",
    "        data[f'{f}_diff'] = data[f].diff()\n",
    "\n",
    "        if i == 0:\n",
    "            add_featuers.append(f_mean_name)\n",
    "            add_featuers.append(f_max_name)\n",
    "            add_featuers.append(f_min_name)\n",
    "            add_featuers.append(f_std_name)\n",
    "            add_featuers.append(f_corr_name)\n",
    "            add_featuers.append(f_skew_name)\n",
    "            add_featuers.append(f'{f}_{f_mean_name}_cha')\n",
    "            add_featuers.append(f'{f}_{f_max_name}_cha')\n",
    "            add_featuers.append(f'{f}_{f_min_name}_cha')\n",
    "            add_featuers.append(f'{f}_diff')\n",
    "\n",
    "features.extend(add_featuers)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "# 对所有的特征进行划分\n",
    "for f in features:\n",
    "    if f not in ['weekday','hour', 'ts']:\n",
    "        q = len(data[f].drop_duplicates())\n",
    "\n",
    "        data[f] = pd.qcut(data[f], q=int(q/10), labels=False, duplicates=\"drop\")\n",
    "\n",
    "all_train = data[data['is_train']].reset_index(drop=True)\n",
    "test = data[~data['is_train']].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 删除分布不均衡的特征"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "all_train = all_train.dropna(subset=['Label1', 'Label2']).reset_index(drop=True)\n",
    "def transform(x: pd.Series, c=20):\n",
    "    return np.log1p(x/c)\n",
    "\n",
    "def inverse_transform(x: pd.Series, c = 20):\n",
    "    return np.expm1(x)*c\n",
    "\n",
    "all_train = all_train.dropna(subset=['Label1', 'Label2']).reset_index(drop=True)\n",
    "all_train['Label1'] = transform(all_train['Label1'])\n",
    "label_c = 8\n",
    "all_train['Label2'] = transform(all_train['Label2'], c=label_c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot(y1, y2, x_title, y_title, title):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.plot(range(len(y1)), y1)\n",
    "    plt.plot(range(len(y1)), y2)\n",
    "    plt.legend()\n",
    "    plt.xlabel(x_title)\n",
    "    plt.ylabel(y_title)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:04:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"bagging_seed\", \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:5.70356\tvalidation_1-rmse:5.64786\n",
      "[200]\tvalidation_0-rmse:0.09191\tvalidation_1-rmse:0.10653\n",
      "[400]\tvalidation_0-rmse:0.07775\tvalidation_1-rmse:0.10456\n",
      "[600]\tvalidation_0-rmse:0.06880\tvalidation_1-rmse:0.10326\n",
      "[800]\tvalidation_0-rmse:0.06316\tvalidation_1-rmse:0.10263\n",
      "[1000]\tvalidation_0-rmse:0.05907\tvalidation_1-rmse:0.10200\n",
      "[1200]\tvalidation_0-rmse:0.05586\tvalidation_1-rmse:0.10193\n",
      "[1400]\tvalidation_0-rmse:0.05321\tvalidation_1-rmse:0.10186\n",
      "[1600]\tvalidation_0-rmse:0.05112\tvalidation_1-rmse:0.10186\n",
      "[1724]\tvalidation_0-rmse:0.04989\tvalidation_1-rmse:0.10194\n",
      "score_list = [1324.9579942013347]\n",
      "[10:04:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"bagging_seed\", \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20704/1929984521.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     50\u001B[0m             \u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m3333\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m         )\n\u001B[1;32m---> 52\u001B[1;33m         \u001B[0mmodel2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_train\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mall_train\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     53\u001B[0m         \u001B[0mtest\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minverse_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\38125\\anaconda3\\envs\\python38\\lib\\site-packages\\xgboost\\core.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    573\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 575\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    576\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    577\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\38125\\anaconda3\\envs\\python38\\lib\\site-packages\\xgboost\\sklearn.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[0;32m    959\u001B[0m             \u001B[0mxgb_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0meval_metric\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mearly_stopping_rounds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    960\u001B[0m         )\n\u001B[1;32m--> 961\u001B[1;33m         self._Booster = train(\n\u001B[0m\u001B[0;32m    962\u001B[0m             \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    963\u001B[0m             \u001B[0mtrain_dmatrix\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\38125\\anaconda3\\envs\\python38\\lib\\site-packages\\xgboost\\core.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    573\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 575\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    576\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    577\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\38125\\anaconda3\\envs\\python38\\lib\\site-packages\\xgboost\\training.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[0;32m    179\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcb_container\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbefore_iteration\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbst\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevals\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    180\u001B[0m             \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 181\u001B[1;33m         \u001B[0mbst\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    182\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcb_container\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mafter_iteration\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbst\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevals\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    183\u001B[0m             \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\38125\\anaconda3\\envs\\python38\\lib\\site-packages\\xgboost\\core.py\u001B[0m in \u001B[0;36mupdate\u001B[1;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[0;32m   1776\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1777\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mfobj\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1778\u001B[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001B[0m\u001B[0;32m   1779\u001B[0m                                                     \u001B[0mctypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mc_int\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miteration\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1780\u001B[0m                                                     dtrain.handle))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "score_list = []\n",
    "labels = ['Label1','Label2']\n",
    "test_size = 4000\n",
    "\n",
    "for label in labels:\n",
    "    X_train = all_train[features][:-test_size]\n",
    "    y_train = all_train[label][:-test_size]\n",
    "\n",
    "    X_test = all_train[features][-test_size:]\n",
    "    y_test = all_train[label][-test_size:]\n",
    "    if label == \"Label1\":\n",
    "        model = xgb.XGBRegressor(\n",
    "            max_bin=120,\n",
    "            boosting=\"gbdt\",\n",
    "            max_depth=4,\n",
    "            learning_rate=0.05,\n",
    "            n_estimators=10000,\n",
    "            subsample = 0.8,\n",
    "            colsample_bytree=0.3,\n",
    "            min_child_weight=0.01,\n",
    "            bagging_seed=12,\n",
    "            reg_alpha=1.2,\n",
    "            reg_lambda=1.2,  # 此处不改了\n",
    "            gpu_id=0,\n",
    "            tree_method='gpu_hist',\n",
    "            random_state=3333\n",
    "        )\n",
    "        model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], eval_metric=['rmse'],\n",
    "              early_stopping_rounds=150, verbose=200)\n",
    "\n",
    "        test_pred = model.predict(X_test)\n",
    "        score_list.append(np.sqrt(mean_squared_error(inverse_transform(y_test), inverse_transform(test_pred))))\n",
    "        print(f\"score_list = {score_list}\")\n",
    "        model2 = xgb.XGBRegressor(\n",
    "            max_bin=120,\n",
    "            boosting=\"gbdt\",\n",
    "            max_depth=4,\n",
    "            learning_rate=0.05,\n",
    "            n_estimators=int(1.2*model.best_iteration),\n",
    "            subsample = 0.8,\n",
    "            colsample_bytree=0.3,\n",
    "            min_child_weight=0.01,\n",
    "            bagging_seed=12,\n",
    "            reg_alpha=1.2,\n",
    "            reg_lambda=1.2,  # 此处不改了\n",
    "            gpu_id=0,\n",
    "            tree_method='gpu_hist',\n",
    "            random_state=3333\n",
    "        )\n",
    "        model2.fit(all_train[features], all_train[label])\n",
    "        test[label] = inverse_transform(model2.predict(test[features]))\n",
    "    else:\n",
    "        model = xgb.XGBRegressor(\n",
    "            max_bin=100,\n",
    "            boosting=\"gbdt\",\n",
    "            max_depth=4,\n",
    "            learning_rate=0.03,\n",
    "            n_estimators=10000,\n",
    "            subsample = 0.7,\n",
    "            colsample_bytree=0.4,\n",
    "            min_child_weight=0.01,\n",
    "            bagging_seed=1,\n",
    "            reg_alpha=1.,\n",
    "            reg_lambda=1.,  # 此处不改了\n",
    "            gpu_id=0,\n",
    "            tree_method='gpu_hist',\n",
    "            random_state=1212\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], eval_metric=['rmse'],\n",
    "              early_stopping_rounds=150, verbose=200)\n",
    "        test_pred = model.predict(X_test)\n",
    "        score_list.append(np.sqrt(mean_squared_error(inverse_transform(y_test, c=label_c), inverse_transform(test_pred, c=label_c))))\n",
    "        print(f\"score_list = {score_list}\")\n",
    "        model2 = xgb.XGBRegressor(\n",
    "            max_bin=100,\n",
    "            boosting=\"gbdt\",\n",
    "            max_depth=4,\n",
    "            learning_rate=0.03,\n",
    "            n_estimators=int(1.2*model.best_iteration),\n",
    "            subsample = 0.7,\n",
    "            colsample_bytree=0.4,\n",
    "            min_child_weight=0.01,\n",
    "            bagging_seed=1,\n",
    "            reg_alpha=1.,\n",
    "            reg_lambda=1.,  # 此处不改了\n",
    "            gpu_id=0,\n",
    "            tree_method='gpu_hist',\n",
    "            random_state=1212\n",
    "        )\n",
    "        model2.fit(all_train[features], all_train[label])\n",
    "\n",
    "        test[label] = inverse_transform(model2.predict(test[features]), c=label_c)\n",
    "loss = np.mean(score_list)\n",
    "score = 1000/(1+loss)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6368308776775738\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean(score_list)\n",
    "score = 1000/(1+loss)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "test[['time'] + labels].to_csv(f\"./res/xgboost_res.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6368308776775738\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean(score_list)\n",
    "score = 1000/(1+loss)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "                 time        Label1        Label2\n0      2022/7/18 2:40   9893.540039   9087.713867\n1      2022/7/18 2:42   9907.083008   9334.085938\n2      2022/7/18 2:44  10312.958984   9408.533203\n3      2022/7/18 2:46  10249.574219   9551.273438\n4      2022/7/18 2:48  10107.681641   9286.794922\n...               ...           ...           ...\n9995  2022/7/31 23:50  10742.359375  11269.000977\n9996  2022/7/31 23:52  10797.137695  11517.797852\n9997  2022/7/31 23:54  10866.143555  11444.873047\n9998  2022/7/31 23:56  11019.594727  11510.990234\n9999  2022/7/31 23:58  11599.907227  11546.522461\n\n[10000 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>Label1</th>\n      <th>Label2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022/7/18 2:40</td>\n      <td>9893.540039</td>\n      <td>9087.713867</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022/7/18 2:42</td>\n      <td>9907.083008</td>\n      <td>9334.085938</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022/7/18 2:44</td>\n      <td>10312.958984</td>\n      <td>9408.533203</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022/7/18 2:46</td>\n      <td>10249.574219</td>\n      <td>9551.273438</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022/7/18 2:48</td>\n      <td>10107.681641</td>\n      <td>9286.794922</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>2022/7/31 23:50</td>\n      <td>10742.359375</td>\n      <td>11269.000977</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>2022/7/31 23:52</td>\n      <td>10797.137695</td>\n      <td>11517.797852</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>2022/7/31 23:54</td>\n      <td>10866.143555</td>\n      <td>11444.873047</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>2022/7/31 23:56</td>\n      <td>11019.594727</td>\n      <td>11510.990234</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>2022/7/31 23:58</td>\n      <td>11599.907227</td>\n      <td>11546.522461</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['time'] + labels]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}